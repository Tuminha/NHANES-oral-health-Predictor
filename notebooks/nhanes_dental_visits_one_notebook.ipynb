{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Dental Visits (NHANES) — CatBoost vs XGBoost in one notebook\n",
        "\n",
        "## Why this notebook\n",
        "\n",
        "We'll build a reproducible baseline to predict \"visited a dentist in the last 12 months\" from NHANES demographics + oral-health questionnaire. Focus is on tabular ML best practices: target definition, categorical handling, PR-AUC, threshold policy, and SHAP explanations. Plots use Periospot brand colors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 0 — Setup and brand style\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- Install libs (CatBoost, XGBoost, LightGBM optional, SHAP)\n",
        "- Set Periospot palette once so all plots are consistent\n",
        "- Create images/ and artifacts/ folders\n",
        "- Load brand palette from JSON file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-macosx_11_0_universal2.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: xgboost in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (3.1.1)\n",
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shap in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (0.50.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: pyyaml in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (6.0.2)\n",
            "Requirement already satisfied: pandas in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (2.3.2)\n",
            "Requirement already satisfied: matplotlib in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (3.10.6)\n",
            "Requirement already satisfied: seaborn in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.7.1)\n",
            "Requirement already satisfied: numpy in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (2.3.5)\n",
            "Collecting graphviz (from catboost)\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scipy in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from catboost) (1.16.1)\n",
            "Collecting plotly (from catboost)\n",
            "  Downloading plotly-6.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: six in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from shap) (0.62.1)\n",
            "Requirement already satisfied: cloudpickle in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from shap) (4.15.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from numba>=0.54->shap) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/franciscoteixeirabarbosa/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Collecting narwhals>=1.15.1 (from plotly->catboost)\n",
            "  Downloading narwhals-2.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading catboost-1.2.8-cp311-cp311-macosx_11_0_universal2.whl (27.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m888.8 kB/s\u001b[0m  \u001b[33m0:00:47\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m876.4 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
            "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Downloading plotly-6.5.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m0m\n",
            "\u001b[?25hDownloading narwhals-2.12.0-py3-none-any.whl (425 kB)\n",
            "Installing collected packages: tabulate, narwhals, Mako, graphviz, colorlog, plotly, lightgbm, alembic, optuna, catboost\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [catboost]/10\u001b[0m [catboost]\n",
            "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 alembic-1.17.2 catboost-1.2.8 colorlog-6.10.1 graphviz-0.21 lightgbm-4.6.0 narwhals-2.12.0 optuna-4.6.0 plotly-6.5.0 tabulate-0.9.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# TODO: installs (only if running in a fresh Colab)\n",
        "!pip install catboost xgboost lightgbm shap optuna tabulate pyyaml pandas matplotlib seaborn scikit-learn numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, precision_recall_curve, confusion_matrix, classification_report, f1_score\n",
        "import shap\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier  # optional\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: load brand palette from JSON\n",
        "with open('../brand_palette.json', 'r') as f:\n",
        "    brand_config = json.load(f)\n",
        "\n",
        "colors = brand_config['colors']\n",
        "mpl_config = brand_config['matplotlib']\n",
        "\n",
        "# Set matplotlib defaults\n",
        "plt.rcParams['font.family'] = mpl_config['font_family']\n",
        "plt.rcParams['figure.facecolor'] = colors['white']\n",
        "plt.rcParams['axes.facecolor'] = colors['vanilla_cream']\n",
        "plt.rcParams['axes.labelcolor'] = colors['periospot_blue']\n",
        "plt.rcParams['text.color'] = colors['black']\n",
        "plt.rcParams['axes.edgecolor'] = colors['periospot_blue']\n",
        "plt.rcParams['xtick.color'] = colors['periospot_blue']\n",
        "plt.rcParams['ytick.color'] = colors['periospot_blue']\n",
        "\n",
        "# Set color cycle\n",
        "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[\n",
        "    colors['periospot_blue'], \n",
        "    colors['periospot_red'], \n",
        "    colors['mystic_blue'],\n",
        "    colors['crimson_blaze']\n",
        "])\n",
        "\n",
        "# TODO: brand helper function\n",
        "def savefig(path, dpi=150, bbox_inches='tight'):\n",
        "    \"\"\"Save figure with brand styling defaults\"\"\"\n",
        "    plt.savefig(path, dpi=dpi, bbox_inches=bbox_inches, \n",
        "                facecolor=colors['white'], edgecolor='none')\n",
        "    print(f\"Saved: {path}\")\n",
        "\n",
        "# TODO: ensure folders exist\n",
        "Path(\"../images\").mkdir(exist_ok=True)\n",
        "Path(\"../artifacts\").mkdir(exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1 — Get the data (NHANES oral-health)\n",
        "\n",
        "### Instructions\n",
        "\n",
        "You can use the Kaggle NHANES dataset (`cdc/national-health-and-nutrition-examination-survey`) or pull files directly from CDC. The **Kaggle dataset comes as CSV files** (not SAS XPT), which makes it easier to work with.\n",
        "\n",
        "For this project, we'll use two components:\n",
        "- **demographic.csv** (demographics): age, sex, race/ethnicity, education, income-to-poverty ratio\n",
        "- **questionnaire.csv** (oral health questionnaire): last dental visit question (target)\n",
        "\n",
        "### Notes on NHANES Variable Mapping\n",
        "\n",
        "- **Join key:** `SEQN` (participant ID)\n",
        "- **Target:** `OHQ030` (\"When was your last dental visit?\")\n",
        "  - Typical coding: 1 = < 6 months, 2 = 6-12 months, 3+ = > 12 months\n",
        "  - Build binary target: positive (1) if codes 1 or 2 (≤ 12 months), else 0\n",
        "  - Exclude missing/refused (77, 99, NaN)\n",
        "- **Features to start with (demographic.csv):**\n",
        "  - `RIDAGEYR` (age, numeric)\n",
        "  - `RIAGENDR` (sex, categorical)\n",
        "  - `RIDRETH1` or `RIDRETH3` (race/ethnicity, categorical)\n",
        "  - `DMDEDUC2` (education level, categorical, adults)\n",
        "  - `INDFMPIR` (income-to-poverty ratio, numeric)\n",
        "  - Optional: `DMDMARTL` (marital), `DMDBORN4` (country of birth), etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DEMOGRAPHIC DATA (demographic.csv)\n",
            "============================================================\n",
            "Shape: (10175, 47) (rows, columns)\n",
            "\n",
            "Key columns available:\n",
            "  - SEQN, RIDAGEYR, RIAGENDR, RIDRETH3, DMDEDUC2, INDFMPIR\n",
            "\n",
            "First 5 rows of key demographic columns:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SEQN</th>\n",
              "      <th>RIDAGEYR</th>\n",
              "      <th>RIAGENDR</th>\n",
              "      <th>RIDRETH3</th>\n",
              "      <th>DMDEDUC2</th>\n",
              "      <th>INDFMPIR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>73557</td>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73558</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>73559</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73560</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73561</td>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SEQN  RIDAGEYR  RIAGENDR  RIDRETH3  DMDEDUC2  INDFMPIR\n",
              "0  73557        69         1         4       3.0      0.84\n",
              "1  73558        54         1         3       3.0      1.78\n",
              "2  73559        72         1         3       4.0      4.51\n",
              "3  73560         9         1         3       NaN      2.52\n",
              "4  73561        73         2         3       5.0      5.00"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "QUESTIONNAIRE DATA (questionnaire.csv)\n",
            "============================================================\n",
            "Shape: (10175, 953) (rows, columns)\n",
            "\n",
            "OHQ columns (oral health related): 53 columns\n",
            "\n",
            "First 5 rows of OHQ columns (showing first 6 OHQ columns):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SEQN</th>\n",
              "      <th>OHQ030</th>\n",
              "      <th>OHQ033</th>\n",
              "      <th>OHQ770</th>\n",
              "      <th>OHQ780A</th>\n",
              "      <th>OHQ780B</th>\n",
              "      <th>OHQ780C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>73557</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73558</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>73559</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>73560</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73561</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SEQN  OHQ030  OHQ033  OHQ770  OHQ780A  OHQ780B  OHQ780C\n",
              "0  73557     6.0     4.0     2.0      NaN      NaN      NaN\n",
              "1  73558     6.0     3.0     1.0     10.0      NaN      NaN\n",
              "2  73559     1.0     1.0     2.0      NaN      NaN      NaN\n",
              "3  73560     1.0     1.0     2.0      NaN      NaN      NaN\n",
              "4  73561     1.0     1.0     2.0      NaN      NaN      NaN"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TARGET VARIABLE: OHQ030 ('When was your last dental visit?')\n",
            "============================================================\n",
            "OHQ030 value meanings:\n",
            "  1.0 = Less than 6 months ago\n",
            "  2.0 = 6 months to less than 1 year ago\n",
            "  3.0 = 1 year to less than 2 years ago\n",
            "  4.0 = 2 years to less than 3 years ago\n",
            "  5.0 = 3 years to less than 5 years ago\n",
            "  6.0 = 5 years or more ago\n",
            "  7.0 = Never\n",
            "  77.0 = Refused\n",
            "  99.0 = Don't know\n",
            "\n",
            "Value counts:\n",
            "OHQ030\n",
            "1.0     4632\n",
            "2.0     1510\n",
            "3.0      980\n",
            "4.0      592\n",
            "5.0      480\n",
            "6.0      913\n",
            "7.0      650\n",
            "77.0       2\n",
            "99.0       9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Missing values: 407\n"
          ]
        }
      ],
      "source": [
        "# TODO: (option A) Kaggle CLI download to data/raw (already done if files exist)\n",
        "# !kaggle datasets download -d cdc/national-health-and-nutrition-examination-survey -p ../data/raw\n",
        "# !unzip -o ../data/raw/national-health-and-nutrition-examination-survey.zip -d ../data/raw\n",
        "\n",
        "# NOTE: Kaggle dataset comes as CSV files, not SAS XPT\n",
        "# Load demographic and questionnaire data from CSV\n",
        "import pandas as pd\n",
        "\n",
        "demo = pd.read_csv(\"../data/raw/demographic.csv\")\n",
        "ohq = pd.read_csv(\"../data/raw/questionnaire.csv\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DEMOGRAPHIC DATA (demographic.csv)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {demo.shape} (rows, columns)\")\n",
        "print(f\"\\nKey columns available:\")\n",
        "key_demo_cols = ['SEQN', 'RIDAGEYR', 'RIAGENDR', 'RIDRETH3', 'DMDEDUC2', 'INDFMPIR']\n",
        "print(f\"  - {', '.join([c for c in key_demo_cols if c in demo.columns])}\")\n",
        "print(\"\\nFirst 5 rows of key demographic columns:\")\n",
        "display(demo[key_demo_cols].head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"QUESTIONNAIRE DATA (questionnaire.csv)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {ohq.shape} (rows, columns)\")\n",
        "print(f\"\\nOHQ columns (oral health related): {len([c for c in ohq.columns if 'OHQ' in c])} columns\")\n",
        "ohq_cols = ['SEQN'] + [c for c in ohq.columns if 'OHQ' in c]\n",
        "print(f\"\\nFirst 5 rows of OHQ columns (showing first 6 OHQ columns):\")\n",
        "display(ohq[ohq_cols[:7]].head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TARGET VARIABLE: OHQ030 ('When was your last dental visit?')\")\n",
        "print(\"=\"*60)\n",
        "print(\"OHQ030 value meanings:\")\n",
        "print(\"  1.0 = Less than 6 months ago\")\n",
        "print(\"  2.0 = 6 months to less than 1 year ago\")\n",
        "print(\"  3.0 = 1 year to less than 2 years ago\")\n",
        "print(\"  4.0 = 2 years to less than 3 years ago\")\n",
        "print(\"  5.0 = 3 years to less than 5 years ago\")\n",
        "print(\"  6.0 = 5 years or more ago\")\n",
        "print(\"  7.0 = Never\")\n",
        "print(\"  77.0 = Refused\")\n",
        "print(\"  99.0 = Don't know\")\n",
        "print(\"\\nValue counts:\")\n",
        "print(ohq['OHQ030'].value_counts().sort_index())\n",
        "print(f\"\\nMissing values: {ohq['OHQ030'].isna().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged shape: (10175, 999)\n",
            "Note: Both datasets have same SEQN participants, so shape should be similar to demo.shape\n",
            "\n",
            "Selected categorical features: ['RIAGENDR', 'RIDRETH3', 'DMDEDUC2']\n",
            "Selected numeric features: ['RIDAGEYR', 'INDFMPIR']\n",
            "\n",
            "============================================================\n",
            "BUILDING TARGET VARIABLE\n",
            "============================================================\n",
            "OHQ030 value counts before filtering:\n",
            "OHQ030\n",
            "1.0     4632\n",
            "2.0     1510\n",
            "3.0      980\n",
            "4.0      592\n",
            "5.0      480\n",
            "6.0      913\n",
            "7.0      650\n",
            "77.0       2\n",
            "99.0       9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Missing (NaN): 407\n",
            "\n",
            "Valid responses (codes 1-7): 9757\n",
            "Invalid/refused/missing: 418\n",
            "\n",
            "Dataframe after filtering: (9757, 999)\n",
            "\n",
            "Target distribution:\n",
            "target\n",
            "0    3615\n",
            "1    6142\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Target distribution (proportions):\n",
            "target\n",
            "0    0.370503\n",
            "1    0.629497\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class balance: 0.629 = 62.9% visited within 12 months\n"
          ]
        }
      ],
      "source": [
        "# TODO: merge on SEQN (inner join), keep needed columns only\n",
        "df = demo.merge(ohq, on=\"SEQN\", how=\"inner\")\n",
        "print(f\"Merged shape: {df.shape}\")\n",
        "print(f\"Note: Both datasets have same SEQN participants, so shape should be similar to demo.shape\")\n",
        "\n",
        "# TODO: select feature columns from demographic data\n",
        "# Key columns explanation:\n",
        "# - SEQN: Participant ID (join key, not a feature)\n",
        "# - RIDAGEYR: Age in years (numeric)\n",
        "# - RIAGENDR: Sex (1=Male, 2=Female) - categorical\n",
        "# - RIDRETH3: Race/ethnicity (detailed categories) - categorical\n",
        "# - DMDEDUC2: Education level (adults 20+) - categorical\n",
        "# - INDFMPIR: Income-to-poverty ratio (numeric, higher = better off)\n",
        "\n",
        "cat_cols = ['RIAGENDR', 'RIDRETH3', 'DMDEDUC2']  # categorical features\n",
        "num_cols = ['RIDAGEYR', 'INDFMPIR']  # numeric features\n",
        "\n",
        "# Optional: add more features if available\n",
        "# cat_cols.extend(['DMDMARTL', 'DMDBORN4'])  # marital status, country of birth\n",
        "\n",
        "print(f\"\\nSelected categorical features: {cat_cols}\")\n",
        "print(f\"Selected numeric features: {num_cols}\")\n",
        "\n",
        "# TODO: build target from OHQ030\n",
        "# OHQ030 coding (from NHANES documentation):\n",
        "# 1.0 = Less than 6 months ago → TARGET = 1 (visited within 12 months)\n",
        "# 2.0 = 6 months to less than 1 year ago → TARGET = 1 (visited within 12 months)\n",
        "# 3.0+ = More than 1 year ago → TARGET = 0 (did NOT visit within 12 months)\n",
        "# 77.0 = Refused → exclude\n",
        "# 99.0 = Don't know → exclude\n",
        "# NaN = Missing → exclude\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUILDING TARGET VARIABLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# First, check OHQ030 distribution\n",
        "print(\"OHQ030 value counts before filtering:\")\n",
        "print(df['OHQ030'].value_counts().sort_index())\n",
        "print(f\"\\nMissing (NaN): {df['OHQ030'].isna().sum()}\")\n",
        "\n",
        "# Filter out invalid responses (refused, don't know, missing)\n",
        "valid_mask = df['OHQ030'].isin([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0])\n",
        "print(f\"\\nValid responses (codes 1-7): {valid_mask.sum()}\")\n",
        "print(f\"Invalid/refused/missing: {(~valid_mask).sum()}\")\n",
        "\n",
        "# Keep only valid responses\n",
        "df = df[valid_mask].copy()\n",
        "print(f\"\\nDataframe after filtering: {df.shape}\")\n",
        "\n",
        "# Create binary target: 1 if visited within 12 months (codes 1 or 2), else 0\n",
        "df['target'] = df['OHQ030'].isin([1.0, 2.0]).astype(int)\n",
        "\n",
        "print(\"\\nTarget distribution:\")\n",
        "target_counts = df['target'].value_counts().sort_index()\n",
        "print(target_counts)\n",
        "print(\"\\nTarget distribution (proportions):\")\n",
        "print(df['target'].value_counts(normalize=True).sort_index())\n",
        "print(f\"\\nClass balance: {df['target'].mean():.3f} = {df['target'].mean()*100:.1f}% visited within 12 months\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2 — Clean, missingness, and basic EDA\n",
        "\n",
        "### Instructions\n",
        "\n",
        "- Handle missing values: numeric → median; categoricals → most frequent (document it)\n",
        "- Plot class balance and a couple of feature vs target brand-styled charts\n",
        "- Keep EDA minimal; focus on modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: minimal cleaning (drop unused columns, clip outliers if any, cast categoricals)\n",
        "# Keep only feature columns + target\n",
        "# feature_cols = cat_cols + num_cols\n",
        "# df = df[feature_cols + ['target']].copy()\n",
        "\n",
        "# TODO: handle missing values\n",
        "# For numeric: impute with median\n",
        "# for col in num_cols:\n",
        "#     median_val = df[col].median()\n",
        "#     df[col] = df[col].fillna(median_val)\n",
        "#     print(f\"Imputed {col} with median: {median_val}\")\n",
        "\n",
        "# For categorical: impute with most frequent\n",
        "# for col in cat_cols:\n",
        "#     mode_val = df[col].mode()[0] if len(df[col].mode()) > 0 else df[col].iloc[0]\n",
        "#     df[col] = df[col].fillna(mode_val)\n",
        "#     print(f\"Imputed {col} with mode: {mode_val}\")\n",
        "\n",
        "# TODO: cast categoricals to proper type\n",
        "# for c in cat_cols:\n",
        "#     df[c] = df[c].astype(\"category\")\n",
        "\n",
        "# TODO: check final missingness\n",
        "# print(\"\\nFinal missing values:\")\n",
        "# print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: basic plots with brand styling (save with savefig)\n",
        "\n",
        "# Plot 1: Class balance bar chart\n",
        "# fig, ax = plt.subplots(figsize=(6, 4))\n",
        "# df['target'].value_counts().plot(kind='bar', ax=ax, color=[colors['periospot_blue'], colors['periospot_red']])\n",
        "# ax.set_xlabel('Target (0=No visit, 1=Visited)', fontsize=mpl_config['label_size'])\n",
        "# ax.set_ylabel('Count', fontsize=mpl_config['label_size'])\n",
        "# ax.set_title('Class Balance', fontsize=mpl_config['title_size'], fontweight='bold')\n",
        "# ax.set_xticklabels(['No Visit (>12mo)', 'Visited (≤12mo)'], rotation=0)\n",
        "# savefig('../images/class_balance.png')\n",
        "# plt.close()\n",
        "\n",
        "# Plot 2: Target rate by sex\n",
        "# fig, ax = plt.subplots(figsize=(6, 4))\n",
        "# target_by_sex = df.groupby('RIAGENDR')['target'].mean()\n",
        "# target_by_sex.plot(kind='bar', ax=ax, color=colors['periospot_blue'])\n",
        "# ax.set_xlabel('Sex', fontsize=mpl_config['label_size'])\n",
        "# ax.set_ylabel('Target Rate (Proportion)', fontsize=mpl_config['label_size'])\n",
        "# ax.set_title('Target Rate by Sex', fontsize=mpl_config['title_size'], fontweight='bold')\n",
        "# ax.set_xticklabels(['Male', 'Female'], rotation=0)\n",
        "# savefig('../images/target_rate_by_sex.png')\n",
        "# plt.close()\n",
        "\n",
        "# Plot 3: Target rate by age group (optional)\n",
        "# df['age_group'] = pd.cut(df['RIDAGEYR'], bins=[0, 18, 35, 50, 65, 100], \n",
        "#                           labels=['<18', '18-35', '35-50', '50-65', '65+'])\n",
        "# fig, ax = plt.subplots(figsize=(8, 4))\n",
        "# target_by_age = df.groupby('age_group')['target'].mean()\n",
        "# target_by_age.plot(kind='bar', ax=ax, color=colors['mystic_blue'])\n",
        "# ax.set_xlabel('Age Group', fontsize=mpl_config['label_size'])\n",
        "# ax.set_ylabel('Target Rate', fontsize=mpl_config['label_size'])\n",
        "# ax.set_title('Target Rate by Age Group', fontsize=mpl_config['title_size'], fontweight='bold')\n",
        "# savefig('../images/target_rate_by_age.png')\n",
        "# plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3 — Train/test split\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Use a stratified split; we'll report PR-AUC (average precision) and ROC-AUC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: prepare features and target\n",
        "# X = df[cat_cols + num_cols].copy()\n",
        "# y = df['target'].copy()\n",
        "\n",
        "# TODO: stratified train/test split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, \n",
        "#     stratify=y, \n",
        "#     test_size=0.2, \n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# TODO: print split summary\n",
        "# print(f\"Train shape: {X_train.shape}, Target rate: {y_train.mean():.3f}\")\n",
        "# print(f\"Test shape: {X_test.shape}, Target rate: {y_test.mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4 — CatBoost baseline (native categoricals)\n",
        "\n",
        "### Instructions\n",
        "\n",
        "CatBoost handles categoricals without one-hot. Pass column indices for `cat_features`. Optimize for PR-AUC; use early stopping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: get categorical feature indices for CatBoost\n",
        "# cat_idx = [X_train.columns.get_loc(c) for c in cat_cols]\n",
        "# print(f\"Categorical feature indices: {cat_idx}\")\n",
        "\n",
        "# TODO: build CatBoostClassifier with sensible defaults\n",
        "# cat_model = CatBoostClassifier(\n",
        "#     loss='Logloss',\n",
        "#     eval_metric='PRAUC',  # PR-AUC\n",
        "#     depth=6,\n",
        "#     learning_rate=0.05,\n",
        "#     l2_leaf_reg=8,\n",
        "#     iterations=2000,\n",
        "#     early_stopping_rounds=100,\n",
        "#     random_state=42,\n",
        "#     verbose=100  # print every 100 iterations\n",
        "# )\n",
        "\n",
        "# TODO: create Pool objects for training and validation\n",
        "# train_pool = Pool(X_train, y_train, cat_features=cat_idx)\n",
        "# test_pool = Pool(X_test, y_test, cat_features=cat_idx)\n",
        "\n",
        "# TODO: fit model\n",
        "# cat_model.fit(\n",
        "#     train_pool,\n",
        "#     eval_set=test_pool,\n",
        "#     use_best_model=True,\n",
        "#     plot=False\n",
        "# )\n",
        "\n",
        "# TODO: predict probabilities on test set\n",
        "# y_prob_cat = cat_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# TODO: compute PR-AUC and ROC-AUC\n",
        "# pr_auc_cat = average_precision_score(y_test, y_prob_cat)\n",
        "# roc_auc_cat = roc_auc_score(y_test, y_prob_cat)\n",
        "\n",
        "# print(f\"\\nCatBoost Results:\")\n",
        "# print(f\"  PR-AUC: {pr_auc_cat:.4f}\")\n",
        "# print(f\"  ROC-AUC: {roc_auc_cat:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5 — XGBoost baseline (one-hot pipeline)\n",
        "\n",
        "### Instructions\n",
        "\n",
        "For a fair comparison, one-hot encode categoricals in a ColumnTransformer pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: create preprocessing pipeline with one-hot encoding\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     [\n",
        "#         (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop='first'), cat_cols)\n",
        "#     ],\n",
        "#     remainder=\"passthrough\"\n",
        "# )\n",
        "\n",
        "# TODO: build XGBoost classifier\n",
        "# xgb = XGBClassifier(\n",
        "#     n_estimators=1000,\n",
        "#     max_depth=6,\n",
        "#     learning_rate=0.05,\n",
        "#     subsample=0.8,\n",
        "#     colsample_bytree=0.8,\n",
        "#     reg_lambda=1.0,\n",
        "#     reg_alpha=0.1,\n",
        "#     eval_metric=\"aucpr\",  # PR-AUC\n",
        "#     random_state=42,\n",
        "#     tree_method='hist',  # faster\n",
        "#     verbose=0\n",
        "# )\n",
        "\n",
        "# TODO: create pipeline\n",
        "# xgb_pipe = Pipeline([\n",
        "#     (\"prep\", preprocessor),\n",
        "#     (\"clf\", xgb)\n",
        "# ])\n",
        "\n",
        "# TODO: fit pipeline\n",
        "# xgb_pipe.fit(\n",
        "#     X_train, y_train,\n",
        "#     clf__eval_set=[(preprocessor.transform(X_test), y_test)],\n",
        "#     clf__early_stopping_rounds=100,\n",
        "#     clf__verbose=False\n",
        "# )\n",
        "\n",
        "# TODO: predict probabilities\n",
        "# y_prob_xgb = xgb_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# TODO: compute metrics\n",
        "# pr_auc_xgb = average_precision_score(y_test, y_prob_xgb)\n",
        "# roc_auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
        "\n",
        "# print(f\"\\nXGBoost Results:\")\n",
        "# print(f\"  PR-AUC: {pr_auc_xgb:.4f}\")\n",
        "# print(f\"  ROC-AUC: {roc_auc_xgb:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6 — Optional LightGBM third baseline\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Use the same preprocessing as XGBoost (one-hot encoding) for fair comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: build LightGBM classifier\n",
        "# lgbm = LGBMClassifier(\n",
        "#     n_estimators=1500,\n",
        "#     learning_rate=0.05,\n",
        "#     max_depth=-1,  # no limit\n",
        "#     num_leaves=31,\n",
        "#     subsample=0.8,\n",
        "#     colsample_bytree=0.8,\n",
        "#     reg_lambda=1.0,\n",
        "#     reg_alpha=0.1,\n",
        "#     metric='aucpr',  # PR-AUC\n",
        "#     random_state=42,\n",
        "#     verbose=-1\n",
        "# )\n",
        "\n",
        "# TODO: create pipeline (reuse preprocessor from XGBoost)\n",
        "# lgbm_pipe = Pipeline([\n",
        "#     (\"prep\", preprocessor),\n",
        "#     (\"clf\", lgbm)\n",
        "# ])\n",
        "\n",
        "# TODO: fit pipeline\n",
        "# lgbm_pipe.fit(\n",
        "#     X_train, y_train,\n",
        "#     clf__eval_set=[(preprocessor.transform(X_test), y_test)],\n",
        "#     clf__callbacks=[lgbm.early_stopping(stopping_rounds=100, verbose=False)]\n",
        "# )\n",
        "\n",
        "# TODO: predict probabilities\n",
        "# y_prob_lgbm = lgbm_pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# TODO: compute metrics\n",
        "# pr_auc_lgbm = average_precision_score(y_test, y_prob_lgbm)\n",
        "# roc_auc_lgbm = roc_auc_score(y_test, y_prob_lgbm)\n",
        "\n",
        "# print(f\"\\nLightGBM Results:\")\n",
        "# print(f\"  PR-AUC: {pr_auc_lgbm:.4f}\")\n",
        "# print(f\"  ROC-AUC: {roc_auc_lgbm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7 — Threshold policy and calibration (quick)\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Kaggle uses probabilities; for policy we pick a threshold that maximizes recall subject to min precision (e.g., 0.25). Also show a reliability curve if you add calibration later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: use precision_recall_curve to find optimal threshold\n",
        "# Use best model (e.g., CatBoost)\n",
        "# precision, recall, thresholds = precision_recall_curve(y_test, y_prob_cat)\n",
        "\n",
        "# TODO: find threshold that maximizes recall subject to min precision >= 0.25\n",
        "# min_precision = 0.25\n",
        "# valid_idx = precision >= min_precision\n",
        "# if valid_idx.any():\n",
        "#     best_idx = np.argmax(recall[valid_idx])\n",
        "#     threshold_star = thresholds[valid_idx][best_idx]\n",
        "#     precision_at_tstar = precision[valid_idx][best_idx]\n",
        "#     recall_at_tstar = recall[valid_idx][best_idx]\n",
        "# else:\n",
        "#     # fallback: use threshold at max F1\n",
        "#     f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
        "#     best_idx = np.argmax(f1_scores)\n",
        "#     threshold_star = thresholds[best_idx]\n",
        "#     precision_at_tstar = precision[best_idx]\n",
        "#     recall_at_tstar = recall[best_idx]\n",
        "\n",
        "# TODO: compute F1 and F2 at threshold_star\n",
        "# y_pred_at_tstar = (y_prob_cat >= threshold_star).astype(int)\n",
        "# f1_at_tstar = f1_score(y_test, y_pred_at_tstar)\n",
        "# f2_at_tstar = (1 + 2**2) * (precision_at_tstar * recall_at_tstar) / (2**2 * precision_at_tstar + recall_at_tstar + 1e-10)\n",
        "\n",
        "# print(f\"\\nThreshold Policy (min precision ≥ 0.25):\")\n",
        "# print(f\"  Optimal threshold t*: {threshold_star:.4f}\")\n",
        "# print(f\"  Precision@t*: {precision_at_tstar:.4f}\")\n",
        "# print(f\"  Recall@t*: {recall_at_tstar:.4f}\")\n",
        "# print(f\"  F1@t*: {f1_at_tstar:.4f}\")\n",
        "# print(f\"  F2@t*: {f2_at_tstar:.4f}\")\n",
        "\n",
        "# TODO: plot precision-recall curve with threshold marked\n",
        "# fig, ax = plt.subplots(figsize=(8, 6))\n",
        "# ax.plot(recall, precision, color=colors['periospot_blue'], linewidth=2, label='PR Curve')\n",
        "# ax.axvline(recall_at_tstar, color=colors['periospot_red'], linestyle='--', \n",
        "#            label=f'Threshold t*={threshold_star:.3f}')\n",
        "# ax.axhline(min_precision, color=colors['crimson_blaze'], linestyle=':', \n",
        "#            label=f'Min precision={min_precision}')\n",
        "# ax.set_xlabel('Recall', fontsize=mpl_config['label_size'])\n",
        "# ax.set_ylabel('Precision', fontsize=mpl_config['label_size'])\n",
        "# ax.set_title('Precision-Recall Curve', fontsize=mpl_config['title_size'], fontweight='bold')\n",
        "# ax.legend()\n",
        "# ax.grid(True, alpha=0.3)\n",
        "# savefig('../images/pr_curve_with_threshold.png')\n",
        "# plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 8 — SHAP explanations (CatBoost)\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Global feature importance with SHAP TreeExplainer on CatBoost. Use a 1–2k sample for speed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: sample test set for SHAP (1-2k samples for speed)\n",
        "# sample_size = min(2000, len(X_test))\n",
        "# sample_idx = np.random.choice(len(X_test), size=sample_size, replace=False)\n",
        "# X_test_sample = X_test.iloc[sample_idx]\n",
        "\n",
        "# TODO: create SHAP explainer\n",
        "# explainer = shap.TreeExplainer(cat_model)\n",
        "\n",
        "# TODO: compute SHAP values\n",
        "# shap_values = explainer.shap_values(X_test_sample)\n",
        "\n",
        "# TODO: plot SHAP summary (brand-styled)\n",
        "# fig, ax = plt.subplots(figsize=(10, 8))\n",
        "# shap.summary_plot(shap_values, X_test_sample, show=False, plot_type=\"bar\",\n",
        "#                   color=colors['periospot_blue'])\n",
        "# ax.set_title('SHAP Feature Importance (CatBoost)', \n",
        "#              fontsize=mpl_config['title_size'], fontweight='bold')\n",
        "# savefig('../images/shap_summary_catboost_bar.png')\n",
        "# plt.close()\n",
        "\n",
        "# TODO: plot SHAP summary (detailed dot plot)\n",
        "# fig, ax = plt.subplots(figsize=(10, 8))\n",
        "# shap.summary_plot(shap_values, X_test_sample, show=False, \n",
        "#                   plot_type=\"dot\", max_display=15)\n",
        "# savefig('../images/shap_summary_catboost_dot.png')\n",
        "# plt.close()\n",
        "\n",
        "# TODO: plot SHAP waterfall for a single instance (optional)\n",
        "# instance_idx = 0\n",
        "# shap.waterfall_plot(explainer.expected_value, shap_values[instance_idx], \n",
        "#                     X_test_sample.iloc[instance_idx], show=False)\n",
        "# savefig('../images/shap_waterfall_example.png')\n",
        "# plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 9 — Compare models and save artifacts\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Print a comparison table, save the best model, and write metrics to JSON.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: create comparison table\n",
        "# from tabulate import tabulate\n",
        "# \n",
        "# comparison = [\n",
        "#     ['Model', 'PR-AUC', 'ROC-AUC'],\n",
        "#     ['CatBoost', f'{pr_auc_cat:.4f}', f'{roc_auc_cat:.4f}'],\n",
        "#     ['XGBoost', f'{pr_auc_xgb:.4f}', f'{roc_auc_xgb:.4f}'],\n",
        "# ]\n",
        "# \n",
        "# # Add LightGBM if trained\n",
        "# # comparison.append(['LightGBM', f'{pr_auc_lgbm:.4f}', f'{roc_auc_lgbm:.4f}'])\n",
        "# \n",
        "# print(\"\\nModel Comparison:\")\n",
        "# print(tabulate(comparison, headers='firstrow', tablefmt='grid'))\n",
        "\n",
        "# TODO: determine best model (by PR-AUC)\n",
        "# best_model_name = 'CatBoost'  # or compare and select\n",
        "# best_model = cat_model  # or select accordingly\n",
        "# best_pr_auc = pr_auc_cat\n",
        "\n",
        "# TODO: save best model\n",
        "# joblib.dump(best_model, '../artifacts/best_model_catboost.joblib')\n",
        "# print(f\"\\nSaved best model: {best_model_name}\")\n",
        "\n",
        "# TODO: save metrics to JSON\n",
        "# metrics_dict = {\n",
        "#     'model': best_model_name,\n",
        "#     'pr_auc': float(best_pr_auc),\n",
        "#     'roc_auc': float(roc_auc_cat),\n",
        "#     'threshold': float(threshold_star),\n",
        "#     'precision_at_threshold': float(precision_at_tstar),\n",
        "#     'recall_at_threshold': float(recall_at_tstar),\n",
        "#     'f1_at_threshold': float(f1_at_tstar),\n",
        "#     'test_size': len(y_test),\n",
        "#     'train_size': len(y_train),\n",
        "#     'target_rate_train': float(y_train.mean()),\n",
        "#     'target_rate_test': float(y_test.mean())\n",
        "# }\n",
        "# \n",
        "# with open('../artifacts/metrics.json', 'w') as f:\n",
        "#     json.dump(metrics_dict, f, indent=2)\n",
        "# \n",
        "# print(\"\\nSaved metrics to artifacts/metrics.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 10 — Mini model card\n",
        "\n",
        "### Model Card Template\n",
        "\n",
        "Fill in the blanks below:\n",
        "\n",
        "- **Dataset:** NHANES cycle ___ (year), components DEMO + OHQ\n",
        "- **Target:** last dental visit ≤ 12 months (derived from OHQ030)\n",
        "- **Train/test:** stratified 80/20 split, seed 42\n",
        "- **Metrics (test):** \n",
        "  - PR-AUC: ___\n",
        "  - ROC-AUC: ___\n",
        "  - Recall@t*: ___\n",
        "  - Precision@t*: ___\n",
        "- **Top drivers (SHAP):** [list top 5 features from SHAP plot]\n",
        "- **Caveats:** \n",
        "  - Survey design weights ignored\n",
        "  - Not clinical advice\n",
        "  - Demographic bias possible\n",
        "  - Missing data imputation assumptions (median/mode)\n",
        "  - Model trained on single NHANES cycle; may not generalize to other cycles\n",
        "\n",
        "### What you learned in this notebook\n",
        "\n",
        "- Clean definition of y from a real public-health dataset\n",
        "- Why CatBoost shines with many categoricals\n",
        "- How PR-AUC and a recall-first threshold change decisions\n",
        "- Using SHAP to make the model intelligible\n",
        "- Brand-consistent visuals without re-importing helpers across files\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Codecademy ML",
      "language": "python",
      "name": "codeacademy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
